{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exist\n",
      "['2.jpg', '0.jpg', '1.jpg', '3.jpg']\n",
      "[True]\n",
      "[True]\n",
      "[True]\n",
      "[False]\n",
      "['2.jpg', '0.jpg', '4.jpg', '1.jpg', '3.jpg']\n",
      "[True]\n",
      "[True]\n",
      "[True]\n",
      "[True]\n",
      "[False]\n",
      "['5.jpg', '2.jpg', '0.jpg', '4.jpg', '1.jpg', '3.jpg']\n",
      "[True]\n",
      "[True]\n",
      "[True]\n",
      "[True]\n",
      "[True]\n",
      "[False]\n",
      "['5.jpg', '2.jpg', '6.jpg', '0.jpg', '4.jpg', '1.jpg', '3.jpg']\n",
      "[True]\n",
      "[True]\n",
      "[True]\n",
      "[True]\n",
      "[True]\n",
      "[True]\n",
      "[False]\n",
      "['5.jpg', '2.jpg', '6.jpg', '0.jpg', '4.jpg', '7.jpg', '1.jpg', '3.jpg']\n",
      "[True]\n",
      "[True]\n",
      "[True]\n",
      "[True]\n",
      "[True]\n",
      "[True]\n",
      "[True]\n",
      "[False]\n",
      "['5.jpg', '2.jpg', '6.jpg', '0.jpg', '4.jpg', '8.jpg', '7.jpg', '1.jpg', '3.jpg']\n",
      "[False]\n",
      "[False]\n",
      "[True]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[True]\n",
      "[False]\n",
      "[True]\n",
      "['5.jpg', '2.jpg', '6.jpg', '9.jpg', '0.jpg', '4.jpg', '8.jpg', '7.jpg', '1.jpg', '3.jpg']\n",
      "[False]\n",
      "[False]\n",
      "[True]\n",
      "[True]\n",
      "[False]\n",
      "[False]\n",
      "[False]\n",
      "[True]\n",
      "[False]\n",
      "[True]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "import os\n",
    "import face_recognition as fr\n",
    "cap =cv2.VideoCapture(0)\n",
    "'''\n",
    "width=640\n",
    "height = 480\n",
    "os.environ[\"OPENCV_FFMPEG_CAPTURE_OPTIONS\"] = \"rtsp_transport;udp\"\n",
    "cap=cv2.VideoCapture(\"rtsp://192.168.10.73:554/onvif1\",cv2.CAP_FFMPEG)\n",
    "cap.set(3,width)\n",
    "cap.set(4,height)\n",
    "'''\n",
    "detector=dlib.get_frontal_face_detector()\n",
    "dir_name=\"/home/prem/Desktop/summer/project1/images/\"\n",
    "try:\n",
    "    os.mkdir(dir_name)\n",
    "except:\n",
    "    print(\"Directory already exist\")\n",
    "\n",
    "count=0\n",
    "known_face_encodings_list=[]\n",
    "\n",
    "while cap.isOpened():\n",
    "    status,frame=cap.read()\n",
    "    #gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    rgb_frame=frame[:,:,::-1]\n",
    "    faces=fr.face_locations(rgb_frame)\n",
    "    for (top,right,bottom,left) in faces:\n",
    "        #cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "        images=os.listdir(dir_name)\n",
    "        print(images)\n",
    "        if len(images)==0:\n",
    "            cv2.imwrite(dir_name+\"/\"+str(count)+\".jpg\",rgb_frame)\n",
    "            #known_face_encoding=fr.face_encodings(known_face)\n",
    "        else:\n",
    "            counter=[]\n",
    "            for image in images:\n",
    "                counter.append(int(image.split(\".\")[0]))\n",
    "                count=max(counter)+1\n",
    "                image_path=dir_name+\"/\"+image\n",
    "                known_face= fr.load_image_file(image_path)#\n",
    "                known_face_encoding=fr.face_encodings(known_face)[0]\n",
    "                #print(\"**\",known_face_encoding)\n",
    "                #known_face_encodings_list.append(known_face_encoding)\n",
    "                face_locations=fr.face_locations(rgb_frame)\n",
    "                #getting face encodings\n",
    "                current_face_encoding=fr.face_encodings(rgb_frame,face_locations)\n",
    "                #print(\"****\",current_face_encoding)\n",
    "                for face_encoding in current_face_encoding:\n",
    "                    matches=fr.compare_faces([known_face_encoding],face_encoding)\n",
    "                    print(matches)\n",
    "                    if True in matches:\n",
    "                        pass\n",
    "                    else:\n",
    "                        cv2.imwrite(dir_name+\"/\"+str(count)+\".jpg\",rgb_frame)\n",
    "                        break\n",
    "                        \n",
    "              \n",
    "        \n",
    "    cv2.imshow(\"live\",frame)\n",
    "    if (cv2.waitKey(50) & 0xff==ord('q')):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#The below cell contains the function to convert image data into numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[36, 33, 32, ..., 82, 84, 84],\n",
       "         [34, 31, 30, ..., 81, 83, 85],\n",
       "         [32, 29, 28, ..., 80, 82, 84],\n",
       "         ...,\n",
       "         [93, 94, 92, ..., 77, 75, 72],\n",
       "         [93, 94, 93, ..., 79, 77, 74],\n",
       "         [92, 91, 92, ..., 78, 77, 75]], dtype=uint8)], [0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def training_dataset_and_labels():\n",
    "    #import haar file\n",
    "    face_cascade=cv2.CascadeClassifier(\"haarcascade_frontalface.xml\")\n",
    "    dir_name=\"/home/prem/Desktop/summer/project1/images\"\n",
    "    #creating features and labels\n",
    "    face_data=[]\n",
    "    labels=[]\n",
    "    for i in os.listdir(dir_name):\n",
    "        image_path=dir_name+\"/\"+i\n",
    "        image=cv2.imread(image_path)\n",
    "        gray=cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "        #face_detection in read images\n",
    "        faces=face_cascade.detectMultiScale(gray,1.15,5)\n",
    "        for (x,y,w,h) in faces:\n",
    "            face_data.append(gray[y:y+h,x:x+w])\n",
    "            part=i.split(\".\")[0]\n",
    "            labels.append(int(part))      \n",
    "    np.save('trainfacedata',face_data)\n",
    "    np.save('trainlabels',labels)\n",
    "    #print(len(face_data))\n",
    "    #print(len(labels))\n",
    "    return face_data,labels\n",
    "training_dataset_and_labels()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
